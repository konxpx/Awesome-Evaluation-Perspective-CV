# Awesome-Evaluation-Perspective-CV


Introduction

* [IEEE'2021]"Explaining deep neural networks and beyond: A review of methods and applications",W. Samek, G. Montavon, S. Lapuschkin,C.J.Anders,andK.R.M¨uller.[paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9369420)
* [IEEE'2023]"Object Detection in 20 Years: A Survey",Z. Zou, K. Chen, Z. Shi, Y. Guo, and J. Ye.[paper](https://arxiv.org/pdf/1905.05055)
* [IEEE'1998]"Gradient-based learning applied to document recognition",Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner.[paper](https://axon.cs.byu.edu/~martinez/classes/678/Papers/Convolution_nets.pdf)
* [CVPR'2004]"Learning generative visual models from few training examples: An incremental bayesian approach tested on 101 object categories,",L. Fei-Fei, R. Fergus, and P. Perona.[paper](https://cs.nyu.edu/~fergus/papers/Fei-Fei_GMBV04.pdf)
* [CVPR'2009]"Imagenet: A large-scale hierarchical image database",J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei.[paper](https://image-net.org/static_files/papers/imagenet_cvpr09.pdf) [Dataset](https://www.image-net.org)
* [IJCV'2015]"Imagenet large scale visual recognition challenge",O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein et al.[paper](https://arxiv.org/pdf/1409.0575)
* [CVIU'2017]"Computer vision for assistive technologies",M. Leo, G. Medioni, M. Trivedi, T. Kanade, and G. M. Farinella.
* "Ai and the everything in the whole wide world benchmark",I. D. Raji, E. M. Bender, A. Paullada, E. Denton, and A. Hanna.[paper](https://arxiv.org/pdf/2111.15366)
* [PAMI'2024]"Physical adversarial attack meets computer vision: A decade survey",H. Wei, H. Tang, X. Jia, Z. Wang, H. Yu, Z. Li, S. Satoh, L. Van Gool, and Z. Wang.[paper](https://arxiv.org/pdf/2209.15179)
* "Large language models for robotics: Opportunities, challenges, and perspectives",
J. Wang, Z. Wu, Y. Li, H. Jiang, P. Shu, E. Shi, H. Hu, C. Ma, Y. Liu, X. Wang et al.[paper](https://arxiv.org/pdf/2401.04334)
* "Large language models meet computer vision: A brief survey",R. Hamadi.[paper](https://arxiv.org/pdf/2311.16673)
* [IJCV'2015]"The pascal visual object classes challenge: A retrospective",M. Everingham, S. A. Eslami, L. Van Gool, C. K. Williams, J. Winn, and A. Zisserman[paper](https://homepages.inf.ed.ac.uk/ckiw/postscript/ijcv_voc14.pdf)

Visual Capability - Clarifying The Evaluation Goals

1.Biologically Inspired Visual Capabilities

* [Jocn'2021]"Convolutional neural networks as a model of the visual system: Past, present, and future",G. W. Lindsay.[paper](https://arxiv.org/pdf/2001.07092)
* [nature'2015]"Deep learning",Y. LeCun, Y. Bengio, and G. Hinton.[paper](https://www.nature.com/articles/nature14539)
* [CVPR'2016]"Deep residual learning for image recognition",K. He, X. Zhang, S. Ren, and J. Sun.[paper](https://arxiv.org/pdf/1512.03385)
* [NeurIPS'2015]"Learning both weights and connections for efffcient neural network",S. Han, J. Pool, J. Tran, and W. Dally.[paper](https://arxiv.org/pdf/1506.02626)
* [NIPS'2017]"Attention is all you need",A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Ł. Kaiser, and I. Polosukhin.[paper](https://arxiv.org/pdf/1706.03762)

2.Cognitive Science Inspiration in Computer Vision

* [Compr. Physiol'2018],"Neural mechanisms of high-level vision",J. Hegde´.[paper](https://www.researchgate.net/publication/326227744_Neural_Mechanisms_of_High-Level_Vision)
* [NIPS'2015]"Faster r-cnn: Towards real-time object detection with region proposal networks",S. Ren, K. He, R. Girshick, and J. Sun.[paper](https://arxiv.org/pdf/1506.01497)
* [CVPR'2007]"Image representations beyond histograms of gradients: The role of gestalt descriptors",S. Bileschi and L. Wolf.[paper](https://www.cs.tau.ac.il/~wolf/papers/gestalt.pdf)
* [PAMI'2007]"Robust object recognition with cortex-like mechanisms",T. Serre, L. Wolf, S. Bileschi, M. Riesenhuber, and T. Poggio.[paper](https://mcgovern.mit.edu/wp-content/uploads/2019/01/04069258.pdf)
* [NIPS'2014]"Two-stream convolutional networks for action recognition in videos",K. Simonyan and A. Zisserman.[paper](https://arxiv.org/pdf/1406.2199)
* [IJCV'2000]"How optimal depth cue integration depends on the task",P. R. Schrater and D. Kersten.[paper](http://vision.psych.umn.edu/users/schrater/SchraterKerstenIJCV2000.pdf)
* "Long short-term memory",A. Graves and A. Graves.[paper](https://arxiv.org/pdf/1308.0850)
* [CVPR'2015]"Long-term recurrent convolutional networks for visual recognition and description",J. Donahue, L. Anne Hendricks, S. Guadarrama, M. Rohrbach, S. Venugopalan, K. Saenko, and T. Darrell.[paper](https://arxiv.org/pdf/1411.4389)
* "The ecological approach to visual perception: classic edition",J. J. Gibson.[paper](https://daughtersofchaos.wordpress.com/wp-content/uploads/2014/05/gibson_occluding-edge_1979.pdf)
* [PAMI'2012]"3d convolutional neural networks for human action recognition",S. Ji, W. Xu, M. Yang, and K. Yu.[paper](http://users.ece.northwestern.edu/~mya671/mypapers/TPAMI13_Ji_Xu_Yang_Yu.pdf)
* [CVPR'2017]"Quo vadis, action recognition? a new model and the kinetics dataset",J. Carreira and A. Zisserman.[paper](https://arxiv.org/pdf/1705.07750)
* "Perception of human motion",R. Blake and M. Shiffrar.[paper](https://www.cs.princeton.edu/courses/archive/spring08/cos598B/Readings/BlakeShiffrar_2007.pdf)
* [T-KDE'2020]"Deep learning on graphs: A survey",Z. Zhang, P. Cui, and W. Zhu[paper](https://arxiv.org/pdf/1812.04202)
* [AAAI'2018]"Spatial temporal graph convolutional networks for skeleton-based action recognition",S. Yan, Y. Xiong, and D. Lin.[paper](https://arxiv.org/pdf/1801.07455)
* [ICCV'2013]"Action recognition with improved trajectories",H. Wang and C. Schmid[paper](https://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Wang_Action_Recognition_with_2013_ICCV_paper.pdf)
* [ECCV'2014]"Categoryspeciffc video summarization",D. Potapov, M. Douze, Z. Harchaoui, and C. Schmid.[paper](https://inria.hal.science/file/index/docid/1022967/filename/video_summarization.pdf)


Proxy Task - Defining the Scope of Evaluation

1.Classification and Recognition

* [MIT'2010]"Vision: A computational investigation into the human representation and processing of visual information",D. Marr.[paper](https://qiongzhang.github.io/Marr.pdf)

2.Detection

* [IJCV'2013]"Selective search for object recognition",J. R. Uijlings, K. E. Van De Sande, T. Gevers, and A. W. Smeulders.[paper](https://pure.uva.nl/ws/files/19494140/UijlingsIJCV2013.pdf)
* [CVPR'2015]"Deep visual-semantic alignments for generating image descriptions",A. Karpathy and L. Fei-Fei.[paper](https://arxiv.org/pdf/1412.2306)
* [ICML'2015]"Show, attend and tell: Neural image caption generation with visual attention",K. Xu, J. Ba, R. Kiros, K. Cho, A. Courville, R. Salakhudinov, R. Zemel, and Y. Bengio.[paper](https://arxiv.org/pdf/1502.03044)
* [TPAMI'2017]"Image captioning and visual question answering based on attributes and external knowledge",Q. Wu, C. Shen, P. Wang, A. Dick, and A. Van Den Hengel.[paper](https://arxiv.org/pdf/1603.02814)
* [CVPR'2018]"High performance visual tracking with siamese region proposal network",B. Li, J. Yan, W. Wu, Z. Zhu, and X. Hu.[paper](https://openaccess.thecvf.com/content_cvpr_2018/papers/Li_High_Performance_Visual_CVPR_2018_paper.pdf)
* [T-AES'2016]"Open set recognition for automatic target classiffcation with rejection",M. D. Scherreik and B. D. Rigling.[paper](https://ieeexplore.ieee.org/document/7472960)
* [PAMI'2020]]"Recent advances in open set recognition: A survey",C. Geng, S.-j. Huang, and S. Chen.[paper](https://arxiv.org/pdf/1811.08581)

3.Segmentation

* [PAMI'2017]"Deeplab: Semantic image segmentation with deep convolutional nets,atrous convolution, and fully connected crfs",L.-C. Chen, G. Papandreou, I. Kokkinos, K. Murphy, and A. L. Yuille.[paper](https://arxiv.org/pdf/1606.00915)
* [ECCV'2018]"Encoder-decoder with atrous separable convolution for semantic image segmentation",L.-C. Chen, Y. Zhu, G. Papandreou, F. Schroff, and H. Adam.[paper](https://arxiv.org/pdf/1802.02611) [Code](https://github.com/tensorflow/models/tree/master/research/deeplab"%3Emodels/research/deeplab)
* [MICCAI'2015]"U-net: Convolutional networks for biomedical image segmentation",O. Ronneberger, P. Fischer, and T. Brox.[paper](https://arxiv.org/pdf/1505.04597) [Code](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/)

4.Tracking

* [TAMI'2021]"Got-10k: A large high-diversity benchmark for generic object tracking in the wild",L. Huang, X. Zhao, and K. Huang.[paper](https://arxiv.org/pdf/1810.11981) [Dataset](http://got-10k.aitestunion.com)
* [TAMI'2023]"Global Instance Tracking: Locating Target More Like Humans",S. Hu, X. Zhao, L. Huang, and K. Huang.[paper](https://www.semanticscholar.org/reader/1f0cb95449984a4346e2a3deca0370cc74cba470) [Dataset](http://videocube.aitestunion.com/)
* [PAMI'2016]"A novel performance evaluation methodology for single-target trackers",M. Kristan, J. Matas, A. Leonardis, T. Voj´ıˇr, R. Pffugfelder, G. Fernandez, G. Nebehay, F. Porikli, and L. Cˇ ehovin.[paper](https://arxiv.org/pdf/1503.01313)
* [IEEE'2020]"Performance evaluation methodology for long-term single-object tracking",A. Lukez´icˇ, L. Cˇ . Zajc, T. Voj´ıˇr, J. Matas, and M. Kristan.[paper](https://ieeexplore.ieee.org/document/9054960)

5.Task Challenges

* [PAMI'2015]"Nus-pro: A new visual tracking challenge",A. Li, M. Lin, Y. Wu, M.-H. Yang, and S. Yan.[paper](https://faculty.ucmerced.edu/mhyang/papers/pami15_nus_pro.pdf)
* [ECCV'2016]"A benchmark and simulator for uav tracking",M. Mueller, N. Smith, and B. Ghanem.[paper](https://link.springer.com/chapter/10.1007/978-3-319-46448-0_27#Sec10)
* [IJCV'2023]"Biodrone: A bionic drone-based single object tracking benchmark for robust vision",X. Zhao, S. Hu, Y. Wang, J. Zhang, Y. Hu, R. Liu, H. Ling, Y. Li, R. Li, K. Liu, and J. Li.[paper](http://biodrone.aitestunion.com/static/BioDrone.pdf) [Dataset](http://biodrone.aitestunion.com/downloads)
* [ICCV'2021]"Transparent object tracking benchmark",H. Fan, H. A. Miththanthaya, S. R. Rajan, X. Liu, Z. Zou, Y. Lin, H. Ling et al.[paper](https://arxiv.org/pdf/2011.10875) [Dataset](https://hengfan2010.github.io/projects/TOTB/)
* [CVPR'2018]"High performance visual tracking with siamese region proposal network",B. Li, J. Yan, W. Wu, Z. Zhu, and X. Hu.[paper](https://openaccess.thecvf.com/content_cvpr_2018/papers/Li_High_Performance_Visual_CVPR_2018_paper.pdf)
* [ECCV'2018]"Distractor-aware siamese networks for visual object tracking",Z. Zhu, Q. Wang, B. Li, W. Wu, J. Yan, and W. Hu.[paper](https://link.springer.com/chapter/10.1007/978-3-030-01240-3_7)







